<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Interactive Text and Images</title>
  <style>
    body {
      font-family: Univers 57 Condensed Oblique, Times New Roman, serif;
      line-height: 1.6;
      margin: 0;
      padding: 20px;
      background-color: #f9f7f1;
      color: #333;
      overflow-x: hidden;
    }
    
    .content {
      max-width: 2000px;
      margin: 0 auto;
      position: relative;
      text-align: justify;
    }
    
    .image-container {
      position: absolute;
      cursor: move;
      transition: transform 0.2s ease, width 0.2s ease;
    }
    
    .image-container img {
      width: 100%;
      height: auto;
      box-shadow: 0 2px 5px rgba(0,0,0,0.2);
    }
    
    .image-container.selected img {
      box-shadow: 0 4px 10px rgba(0,0,0,0.3);
      outline: 2px dashed #e63946;
      outline-offset: 2px;
    }
    
    .image-caption {
      background-color: rgba(255, 255, 255, 0.8);
      padding: 8px;
      font-size: 14px;
      text-align: center;
      border-bottom-left-radius: 5px;
      border-bottom-right-radius: 5px;
      box-shadow: 0 2px 4px rgba(0,0,0,0.1);
      margin-top: -5px; /* Slight overlap with the image */
      font-style: italic;
      color: #444;
    }
    
    /* Ensure the caption stays with the image when dragged */
    .image-container img, .image-caption {
      width: 100%;
      box-sizing: border-box;
    }
    
    .text-content p {
      margin-bottom: 1em;
    }
    
    .controls {
      position: fixed;
      bottom: 20px;
      right: 20px;
      background: rgba(255,255,255,0.8);
      padding: 10px;
      border-radius: 5px;
      box-shadow: 0 2px 5px rgba(0,0,0,0.2);
      z-index: 1000;
    }
    
    .controls button {
      width: 40px;
      height: 40px;
      font-size: 20px;
      margin: 0 5px;
      cursor: pointer;
      border: none;
      background: white;
      border-radius: 50%;
    }
    
    .controls button:hover {
      background: #f0f0f0;
    }
  </style>
</head>
<body>
  <div class="content" id="content">
    <div class="text-content">
      
<h1>the quick brown fox jumps over the lazy dog</h1>

<h2>video installation, projections, publication, flux schnell, SDXL, CLIP, computer generated graphics</h2>
  
<p>What does it mean to mean? This project stems from research conducted to understand the question ‘Can computers understand?’. By focusing on a sentence of a very transparent, almost invisible nature, I want to explore the digital process of information extraction, translation and reconstruction. Using CLIP embeddings, that are a capture of the input's essence or a form of representation of its “meaning”, I aim to present  a different way of the process called ‘understanding’, and challenge its defined and linear status.</p>

<h1>semantic image, digital simulation, language and photography</h1>

<p>This paper is a conclusion of my attempt at understanding computer vision and its relations to ontology, simulation, computing and cognition. After a couple of months of research I was able to distinguish these 4 elements, whose relation to computer vision I found depicting a very vague and distant idea, that I am still to study much longer. The idea comes from my very long-lasting fascination with cognitive neuroscience and epistemology. I always thought the two had a weird relation, both meaning the same ‘thing’, but at the same time in much different areas. Cognitive neuroscience meaning, the study of how our physical brain physically receives, translates and operates physical stimuli, and epistemology as study of the theory of how we interact between our mind and the outside, focusing more on the ‘spiritual’, yet scientific aspect of it. This relationship is what pushed me towards computer vision because it captures perfectly the struggles of modern science. What does it mean to know or to mean? Those were the questions guiding me on this journey. In the first part I will share my reflections that came from early stages of my research, that made me reflect on my practice and what photography or an image means to me. I have become quite distant from what we could consider a ‘standard’ photographic practice, but in spite of that I actually feel very connected, inspired and relevant in this field. I will also discuss what I learned from in class discussions and presentations that were also quite helpful in directing my attention and research into very interesting areas. In the first part of this paper I will talk about photography as a term used to describe art discipline, and my relation to it.</p>

<h2>imageology</h2>

<p>’Imageology’ is a term I propose, because I no longer believe that photography is relevant enough as a means to describe a medium we now mean, when we use that word. There are simply too many battles, dilemmas and unaddressed ambiguities, to continue to carry it in that sense, and we must ‘retreat’ to safe. provable , technically defined way stating that photography can actually only be used to describe practices associated with what we now call ‘analogue’ photography. One of aspects explored by me in my project, and presented in this essay is the similarity of words or their ‘meaning’, ‘to simulate’ and ‘to compute’, because what does it mean ‘to simulate’ if not to artificially compute , and what does it mean ‘to compute’ if not to perform an ‘artificial simulation’.</p>

<h2>to compute : to calculate an answer or amount by using a machine[1]</h2>
<h2>to simulate : to do or make something that looks real but is not real[2]</h2>

<p>This comparison clearly shows they are used to represent different ideas or actions, however that changes when we consider digital photography against those definitions. Digital photography is connected with analogue photography only when we define it as a digital ‘simulation’ of the analogue process, where instead of silver halide crystals (black and white film)[3], the photons and their intensity determine an adequate electron load and are synthesized together by code that in consequence ‘generates’ an image. In no way can you make an argument that those two processes are connected if you are also trying to prove that it is the physical process of light physics that is the essential part between the two. This is because the two methods are quite different, one is a quality of a material described by its physics, and thus the photograph is so close to the original situation as possible, being superior in this regard to for example painting, being more even then a copy because it was created using ‘uniform’ or ‘standardised’ way as a mean to record it, rather than a tool for artistic expression, and the second, an arbitrary way of processing data gathered by detecting the intensity of photons. This can be discovered when taking a closer look at a camera, and counterintuitively, we can see that a camera image sensor does not differentiate between colour of the light, only its intensity, relying on a filter, like a Bayer filter, or grouping certain light frequencies corresponding to individual colours. This distinction is necessary to understand in order to understand my argument concerning the photographic-less nature of my ideas and projects, but what I still refer to as relevant to the field. I decided to include this part of my writing in the first part of it, because I want to describe the space my research has been conducted in. I was very drawn to understanding images in a semantic way, or at least using the same means. Like sonification of images, it reveals the unseen patterns and relations, an aspect of that that truly caught my eye is something called ‘semantic image’,</p>

<h2>a Semantic Image refers to an image that has been analyzed and understood in terms of its meaning, objects, scenes, knowledge, and emotions, through the extraction of features and high-level reasoning in image processing and pattern recognition.[4]</h2>

<p>This refers to a mathematical way of treating (digital) images, where the undefined nature of data that a digital photograph consists of, is used as an advantage and could be treated as a numerological representation. This translation allows for performing image processing and pattern recognition on the ‘translated’ images, and because there is a way to ‘decode’ them back into the original, image file extension can be displayed as an image. This sounds like a complicated operation, but in truth those are just advanced cases, all digital manipulation is happening just like that, with calculation and translation, a layer not present in ‘original’ photography. The reason why I talk about this is that from this point my attention shifted towards the ‘semantic image’ fascination and replaced the ‘original’ photograph. I will discuss this more in the next part, but for now I want to summarise what this paragraph is about. In the beginning I made an argument that points towards this unaddressed ambiguity with the conception of digital photography, that essentially is a simulation of the photographic process. The vital difference between the two is that digital photography is an arbitrary way of interpretation of gathered data, and the physical process that comes directly from chemical properties. This distinction is very important to me as it points me towards thinking about photography as a field connected with images and not necessarily a specific type of process.</p>

<h2>photography : the activity or job of taking photographs or filming[5]</h2>

<h2>photography : the skill or activity of taking or processing photographs</h2>

<p> Those definitions can be found in the Cambridge Dictionary, and they clearly provide us with a coherent definition of what photography is, so how come it still is an issue? In an article I found on Medium, about which we can read this on their website:</p>

<h2>Medium is a publishing platform where people can read important, insightful stories on the topics that matter most to them and share ideas with the world.[6]</h2>

<p>In the article, Thomas Smith who describes himself as ‘seasoned media executive and content creator with extensive experience in visual content and technology’, argues against consideration of AI imagery as photography. I chose this example because it shows in a very clear way the dilemma. His view on the matter is quite simple, there are two key features that describe photography, physical light interaction, and ‘the act of pointing’ as described by curator John Szarkowski. First I want to state an opinion, if something is simple, it's wrong, I think that because nothing ever is simple, we just chose to overlook difficulties and fill in any holes with a certain kind of ‘landlord special’, painting over everything until it looks clean, but without actually cleaning, or making a correct observation.</p>

<h2>Firstly, AI images don’t use light. Unlike real photographs, the lightin them is simulated — dreamed up by the silicon brain of a computer in a distant server farm. Often, the creators of an AI-generated image has little control over the image’s lighting. DALL-E or Midjourney decide what kind of light to simulate based on the scene the tools are generating. Ask for an image of a beautiful person, and you’ll probably get the soft light of a sunrise. Ask for a picture of a hacker, and you’ll get a person in a dark room (probably wearing a hoodie) bathed in the sickly red light of some unseen computer screen.[7]</h2>

<p>This part truly revolts me and I feel the need to comment on it for a bit longer. It is obvious that the author has no idea what AI actually is or how it works. There is no silicon brain, just hundreds of billions of mathematical operations that come together to form probability calculations based on differences and relations completely unachievable for human perception. He makes a good point of the lack of existence of light, but at the same time, a digital image is also just an arbitrary way of simulating, based on real world photons, but an arbitrary system that is highly specialised nonetheless. The professional, or at least competent and educated ones, creators using AI, are not using DALL-E, and Midjourney is not a professional one as well, both considered SotA, but miles behind, Stability AI or Black Forest Labs(this is more of an opinion, but a true one), and to say that they have little control over any aspect of the image is blasphemous and severely uninformed at best. I don't want to go in detail, but any ‘AI creative’, has hundreds of ControlNets, preprocessors, loras, refiners, masks, inpainting possibilities at their disposal enabling them to create quite literally any image they want. The third part of this quote is just adding words to the wordcount I imagine as it is not even communicating anything besides stereotypes stuck in Thomas’s head, but important for this small critique as it demonstrates so clearly the stereotypes he uses and how outdated and fake they are, just like his point.  A big highlight is an example of a project the author mentions, John Kelly’s ‘Boring America Photorealism’, a project where the artist focused on generating generic, soulless, almost accidental and plain-looking images. The project really piqued my interest, but my interest turned to ‘ah, so it's just another white dude’ when I started to read what the artist said about it. Instead of focusing on the technique and the ‘semantics’ of it.</p>

<h2>When Midjourney’s v5 was released and everyone was trying to make professional looking photos, I was trying to make ugly pictures of food.[8]</h2>

<p>When it comes to AI generated art, ego is a big thing to consider, since you rely completely on your tool to do the work, you have to input a lot of thinking and guidance to effectively be able to say with confidence that it is you using the tool, not swinging it blindly. In this case the artist knew what he was doing, even though the vocabulary isn't exactly correct (Midjourney v5*, it is not a model called v5). The photographs are very interesting both artistically and scientifically. This is also where ‘sematic image’, attention mechanisms in transformers and photography come together. The artist was trying to make ‘ordinary’ looking images using stable diffusion. This process is very difficult because of several factors like training data, accuracy, computational power, random seeds etc. Especially because transformers, which is part of the LLM dealing with transforming natural language, use a special feature called attention. Attention (self-attention) mechanism was a groundbreaking step in NLP (natural language processing) and is one of the most important structures in neural networks. This mechanism enables computers to ‘understand’ or take into consideration internal structures and dependencies, making it possible for detecting differences in importance of each word in conveying bigger messages for example, if you would receive a text message from a friend saying three words, name of another friend, ‘hospital’, and ‘come’, you would get a pretty clear idea of the message. The whole sentence could be that because your friends had an accident hey are now in the hospital and need to see you, and just from those three words you can reconstruct a pretty accurate message, but if you would receive the words, ‘had’,’hospital’,’you’, you would not be in a position to perform the same operation. Similarly the self-attention mechanisms allow for the computer to take in the data. This creates tensions and hyperboles in the prompt, if you think about the prompt as a colorful ball covered in rainbow noise, generation guided by the self-attention mechanisms (indirectly) manipulates it into recognizable shapes and sizes that create meaning. This makes it especially difficult to create ‘slow’, ‘normal’ or ‘usual’ looking images. This shows that there is in fact space in AI for control or subtlety, that are recognised tools of artistic expression. This new tool is wrongly accused of mindlessness or triviality, because while we criticise AI and laugh at its graphical inacuracy, in the end it is a working system capable of a degree of ‘understanding’ or connecting information at very least. It is important to note that discussing generativeAI while discussing AI is similar to discussing uranium glass or cosmetics when discussing atomic technologies.</p>

<h1>photography+internet=social media </h1>

<p>A big focus this semester was a group dissection of ‘Why Exhibit’, a publication featuring a collection of essays and conversations with artists, photographers and curators discussing exhibiting photographic works. The collection is edited by Anna-Kaisa Rastenberger and Iris Sikking, and features a number of chapters devoted to different aspects of exhibiting. The part that was mine to digest and present dealt with liquidity of the medium, the more ubiquitous and undefined nature of photography. What I came to consider as the ‘source’ of this quality and of why we cannot exactly say what is photography, I presented in the argument earlier, talking about ‘imageology’. I suspect that it might be the relationship we have with the ‘file format’ of the ‘output' of it, the image. This manifests in a very interesting way in arguments presented in an essay titled ‘Photography without images’[9] by Alise Tifentâle. In this essay we can read that according to Nadya Bair in ‘The Decisive Network: Magnum Photos and the Postwar Image Market’, (2020) during the time of his photo-correspondence from China, photographer Henri Cartier-Bresson actually sent undeveloped rolls back to America to get developed and produced there by his/newspaper’s technicians and/or assistants. This in consequence prompted the author to consider the possibility ‘invisible of photography’, one without images. Cartier, who did not get to see his images before they would be printed in the ‘Life’ magazine and delivered to him, is now one of the most well-known photographers, even if he is long dead . This really shows how weak the definition for what we consider photography is and challenges quite plainly the status of it that questions photography’s ‘liquidity’ in the context of modern times and internet, meanwhile disregarding that its nature was always much more complicated. For now lets focus on the function of photography in relation to mass media, democratisation of arts and the digital revolution[10]. An example I want to discuss is Jon Rafman’s ‘Kool Aid Man in Second Life’(2008-2011), a project done fully in ‘2nd Life’, an early online platform offering fully immersive environments that enable the participants to connect over long distances in the same place, talk and wander the digital landscape. This is a very interesting case, it was presented in my chapter of the aforementioned book, ‘Why Exhibit’, where the author of the article kind of tried to discuss its ‘fascination’. Jon Rafman approaches that space with distance and calculation, in the interview he gave, ‘inside’ the virtual world he described the space as ‘the ultimate tourist destination’[11]. This stance is very visible through his portrayal of the space, in which he recognises the unrealness of it, because how could you think it is a real place you idiot, it is an artificial space.(satirical hyperbole of what Jon Rafman actually does with challenging digital space’s status of ‘realness’, while advocating for its ‘realness’, he questions it instead, his attempt at making an argument in favour, in the end is made from distance and safe coolness of actually not believing in that) While talking about himself and wandering in different spaces, he fetishizes the Internet culture, while remaining cool, dry and safe. This example highlights a quality of photography that is quite distinct to it, separation. This quality manifests in ‘the viewer’s’ inability to observe the photographer. This gives Jon Rafman’s ability to explore and take in the space without being one of the weirdos actually inhabiting it. As a mere visitor he guides us across a landscape of fetishiesed aestheitisicm of the worst sort, of the meaningless exoticism. Almost tangible scream of “Look at those losers here” he shouts, all of course under a facade of “exploration of identity” of groundbreaking cover of contemporary art.</p>

<h2>Gombrowicz trafnie przewidział w ferdydurke, zwłaszcza w operetce, całkowite odwrócenie dominanty estetycznej w kulturze światowej. Gwałtowny wzrost znaczenia ekonomicznego i politycznego niższych warstw społecznych spowodował rozwój niższych form przekazu z definicji plebejskich, takich jak radio, zwłaszcza telewizja. To zaowocowało całkowita dominacja gustu parobka w kulturze, i zepchnęło sztukę na margines. Ostateczne przypieczętowanie tego było wynalezienie internetu, który zatarł granicę między twórca, a odbiorcą wytwarzając, fałszywe z gruntu,  przekonanie że twórca może być każdy.</h2>

<h2>(eng.”Gombrowicz correctly predicted in Ferdydurke, especially in operetta, a complete reversal of aesthetic dominance in world culture. The rapid growth of the economic and political importance of lower social classes resulted in the development of lower forms of communication by definition plebeian, such as radio, especially television. This resulted in the complete domination of the farmhand's taste in culture, and pushed art to the margins. The final seal of this was the invention of the Internet, which blurred the boundary between the creator and the recipient, creating a fundamentally false belief that anyone can be a creator.”)</h2>

<p>This quote is one of my favourites from a polish TV series called “Ranczo”(eng. The Ranch), it remains especially relevant today, when we can see tangible evidence of the future that could almost be prophethed from it. Today, the world is ruled by likes on Instagram, or engagement on Twitter. Complete control and autonomy to anyone with a phone and an internet connection. This global network feeds on images and photographs. In the 2000’s, paparazzi catered to people's needs, in 2010’s smartphones and selfies took over, in 2020’s everyone on the street is armed with a professional grade recording gear, because we love to photograph the sunrise so much. This coupled with everyone being enabled to post and share their own creations, first on platforms like mySpace, later Facebook and now Instagram, is aimed to create an equal and almost democratic space of connection and networking. But that space is a lie, there are multiple[12] articles[13] very[14] well[15] documenting[16] exactly[17] how[18], why[19] and when[20], it is used against its users or even use the users themselves. However it’s power comes from the position we give it inside our society, from the trust we have in it, the access it gives us, convenience etc. We give all this power to social media, because it gives us the ‘promised’ equality, where we can glimpse what it is like to say bad words directly to the Prime Minister, or the President. This ability reinforces our need for relevancy and satisfies it largely. This ties to an idea that Adorno writes about in his article “Commitment” from 1962, where he discusses the political role of art in context of society and rights. Adorno presents the democratisation of culture as a dangerous terrain that allows for misinterpretation, simplifications or unification in the worst case. When discussing Brecht’s ‘The Resistible Rise of Arturo Ui’(1958), where the grotesque and hyperbole that Brecht used to help materialise and simplify, Adorno views as wrong, as it degrades the meaning of the horror what Nazism and 3rd Reich was. Conducting this research has reinforced me with an idea very similar to that one, but perhaps more radical. After familiarising myself with, for example, how LLM's work, I came to a conclusion that simplifications are extremely harmful, and in this case the problem is very visible with how people cannot even understand what ChatGPT is. You cannot just simplify, I was debating it in the context of my upcoming collective assessment and the expectations from the teacher’s team to ‘make our process accessible’ and present our whole process, and yet it is simply impossible to contract so much time into 15 minutes of the presentation, so I need to rely on shortcuts and simplifications that everytime feel wrong, because I know that this discussion requires much, much more time to be fully presented. And this could be also viewed when an simplification is presented in a gallery, it is presented as a simplification, because the simplification is needed for the larger audience to understand. But here is the problem, and it is twofold. Firstly, if the simplification was not needed so would not be the project, as it is more obvious issues, more accessible or discussed to require simplification. Secondly, if we present a simplification, we cannot expect our not-simplified vision to be understood. Those are just some loose thoughts I had after reading Adorno’s article. If we take Adorno’s take on Brecht and apply it to for example AI, we can clearly see the disconnect between what AI is, what it was presented to investors as, what investors presented to their customer, and what the customer actually understood. There are multiple layers of simplifications, simple lies, hyperbole, nuances of each presentation distorts and shifts the actual message. In this case, the dangers are visible to the naked eye everywhere, since we live in the consequences of that. We live in the era of village truths that are perpetuated by the false equality of the internet, that from a place of freedom and expression turned into a maximum security prison guarded by the elders, and if we think AI will turn out any different it is a delusion. The Internet plays a massive role in everyone’s life today, and there is not a single affected person, but that is an illusion that is part of the lie. Not to mention so many ways we have come up with weaponizing social media space, even before that, your location is a factor, device, history, all the data gathered and fed into an algorithm that presents you with a mighty dopamine dose(I also skip talking about if everyone actually is on the internet, who is not, is it another delusion?, internet supply chain and involved logistics and so much more). In her book titled ‘Foto Oko. Wizja fotograficzna wobec okularocentryzmu w sztuce I polowy XX wieku’(eng. Photo Eye. Photographic vision against lenscentrism in art of 1st half of the 20th century) polish art historian and photo-theorist, dr. Dorota Łuczak writes about photography’s position in relation to human perception.</p>

<h2>“Wzrok stał się podstawową metaforą filozoficzną - a wraz ze wzrokiem naoczność stała się ideałem prawdziwości - nie ze względu na jakieś szczególne uprzywilejowanie wzroku wśród zmysłów, lecz dlatego, że bardzo wcześnie narodziła się idea tożsamości filozoficznego pytania o znaczenie z naukowym poszukiwaniem poznania. (...) Wiedzę zdobywa się przez poszukiwanie tego, co przywykliśmy nazywać prawdą, a najwyższą ostateczną formą prawdy poznania jest istotnie naoczność”[21]. W narodzonym z metafizyki światła, okularocentrycznym modelu poznania, - by użyć pojęcia spopularyzowanego przez Martina Jaya - osadza się fotografia. W ten sposób sztuczne, mechaniczne oko aparatu zyskuje autorytet wiarygodnego poznania, który jest jednocześnie wzmacniany poprzez zaprzęgnięcie fotografii do budowy różnorakich systemów wiedzy.[22]</h2>

<h2>(eng.“Sight became the basic philosophical metaphor – and together with sight, intuition became the ideal of truth – not because of any special privilege of sight among the senses, but because the idea of ​​the identity of the philosophical question of meaning with the scientific search for knowledge arose very early on. (...) Knowledge is acquired through the search for what we are accustomed to call truth, and the highest, ultimate form of truth in knowledge is intuition.” Photography is embedded in the ocular-centric model of knowledge born from the metaphysics of light, to use a concept popularized by Martin Jay. In this way, the artificial, mechanical eye of the camera gains the authority of credible knowledge, which is simultaneously reinforced by the harnessing of photography to the construction of various systems of knowledge.)</h2>

<p>This double quote shows the highlight of our relationships with sight, the very simple action that is like an evolutionary reflex we will need to unlearn, sight - belief action - reaction dynamic. We see to believe, and we believe to see, and yet to believe we need to see and sometimes to see we need to believe. This relation is fascinating and in itself leaves so much space to explore and use, but my focus is photographic role in this. With photography we can see, or think we can, what is ‘real’ and all fakes, ghosts and immaterialites fade away before the enlightened ‘wise man’s looking glass’[23]. The title of this paragraph is an equation of a kind, let's solve it. We have photography, the hegemon of cognition and perception, the divine scribe of realities rules, added together with the internet, a failed promised freedom land, that fills the gap after gone equality supplying us with an artificially induced one. They come together to create the most destructive and harmful concoction, one that is set to redefine the world with a collectively self-assured, inclusive and actually completely voluntary group delusion.</p>

<h1>language and/of images</h1>

<p>After talking about the undefined nature of photography, and discussing its newfound democratisation, I want to take on the most important aspect of it, the relation images have with language. Imagine a fox, is it orange? maybe it has white stripes on its fur? pointy ears? little black toes? is it jumping on the grass, or maybe hunting in the forest? Now, of course you imagined it visually in your head, but how? It is not a material object and yet in a way one could argue that it feels like an “image file”, an output that is meant to be read as an image.</p>

<h2>Mental images fill our daydreams, fuel our fancies, and color our memories. People often experience these images as richly detailed, making the imagination seem like a talented artist quickly painting a lifelike scene before our mind’s eye. Our results suggest that while the imagination may indeed be a good artist, it’s on a deadline, and stingy about paint.[24]</h2>

<p>This excerpt from a paper titled ‘Non-commitment in mental imagery’ by Eric J. Bigelow, John P. McCoy and Tomer D. Ullman. Their research confirms mental imagery existence and further investigates the qualities of it, focusing on non-commitment. Mental image is nothing more than a certain stimuli affecting a certain area of the brain. We currently possess technology that uses EEG to decode ‘speech imagery’ directly from your thoughts[25], with a very interesting application discussed here[26]. And this article from 2018[27] describes EEG’s great potential for image reconstruction.</p>

<h2>The fact we can reconstruct what someone experiences visually based on their brain activity opens up a lot of possibilities. It unveils the subjective content of our mind and it provides a way to access, explore and share the content of our perception, memory and imagination.</h2>

<p>This quote, taken from Adrian Nesotor, the researcher behind the system, shows just how powerful AI technology can be and what it can enable us to do. This has led me to think about the future of photography and what it can be? If photography is about capturing reality, which it most definitely is in some way, we can only speculate, but what if we could share our mental images? What if using devices like NeuraLink[28] to even edit or create them too, taking the meaning and boundaries of photography in a completely new direction. This is really made possible by semantics and methods of ‘computing’ meaning like CLIP, or transformers(LLM architecture). This abstract quality of meaning is very interesting when we consider it against for example Broomberg and Chanarin’s ‘Day that nobody died’, where the artists joined british troops in Afghanistan in June of 2008[29] and instead of actual photographic description they captured an abstract image. Together with the story behind it, you can understand the very immaterial idea guiding them in communicating the impossible to literally depict, feeling of the day that nobody died. Another example of this material duplicity, meaning when an object’s presence,is not ‘for’  its ‘purpose,rather than its existence in the first place, is Rudolf Stingel’s ‘Instructions’ where instead of making a painting, replaces it with instructions on how to make one. This subversion is only in the theoretical sense, because in practice it is obvious that process is not the whole thing, but at the same time what is a sum if not an addition of all of its components. This is very interesting for me as to what if there is this ‘theoretical’ photography, where the image is treated much differently and defined in a much separate way and with mountains of precision more. For me that space is the linguistic space, one made up from abstract concepts we agreed what meaning they carry. In that space we can theoretize images, design them with high precision and load them with ‘meaning’ or ‘content’. For me linguistics and what we now call ‘photography’ are inexplicably combined. Connecting the space of the possible and the real.</p>

<h1>reflections</h1>

<p> This semester was very opening for me in realising in what way I want to go as an artist and even though I still have many doubts and troubles I developed a better sense of my practice and the direction I want to take. I charted my course into the newly emerged areas of photography, and from that new viewpoint I found new perspectives that broadened my field of view. I further read into thinkers I feel interested in like Brecht and started to digest  some texts by Adorno that are still extremely helpful with navigating today’s art world. I also pursued my interests in new technologies and used them to produce work or develop a concept, while working on supporting what I do and its relevance with the theoretical side. While I did not find access to the publication Richard Misrach, a photographer I chose for my part of the ‘collective digestion’. His work, while at first I did not think much of it, opened up to me after reading Adorno. I understood the aim and his approach towards society and how his images are actually highly loaded with tension and context, brutally left out on purpose. Misrach’s photography closely aligns with Adorno’s ideas for committed art, present, but not overly didactic. His images capture the current state of things. Without comentig or explicit positioning of the artist, his message remains clear. It is very interesting and in alignment with what I already imagined and thought about art. I am very grateful to have had an opportunity to completely pursue my own interests and ‘agenda’ this semester. I am also grateful to have done so with the class together, who maybe not always  were in a position to understand, but with their questions and conversations helped me a lot with developing the work and methodology behind it. I am very happy to have grown so much thanks to the process, both as an artist, but more importantly as a person. Moreover, thanks to investigations in other areas I feel more confident in my ideas and projects being very closely connected to ‘photography’ or the field that it now is described as. I am also happy to have found so many connections that my research showed me and made me excited about. Cognition, perception, data gathering and processing, digital manipulation, are aspects of digital culture that will be more and more discussed as we progress technologically. This progress always occurs in areas that we never could imagine possible, thats where I want to be, and in my opinion it is where photography is going.
</p>
    </div>
  
<div class="image-container" id="img1" style="left: 0px; top: 0px; width: 200px; z-index: 10;">
  <img src="inspo.jpg" alt="Image 1">
  <div class="image-caption">inspiration behind the process</div>
</div>

<div class="image-container" id="img2" style="left: 0px; top: 0px; width: 250px; z-index: 10;">
  <img src="cover.png" alt="Image 2">
  <div class="image-caption">alternative publication cover</div>
</div>

<div class="image-container" id="img3" style="left: 0px; top: 0px; width: 250px; z-index: 10;">
  <img src="example1.png" alt="Image 3">
  <div class="image-caption">early version screenshot</div>
</div>


  <div class="controls">
    <button id="zoomIn">+</button>
    <button id="zoomOut">−</button>
  </div>

  <script>
    
document.addEventListener('DOMContentLoaded', function() {
  // Elements
  const content = document.getElementById('content');
  const imageContainers = document.querySelectorAll('.image-container');
  const zoomInBtn = document.getElementById('zoomIn');
  const zoomOutBtn = document.getElementById('zoomOut');
  
  // Variables
  let selectedContainer = null;
  let isDragging = false;
  let startX, startY, startLeft, startTop;
  let zoomLevel = 1;
  const zoomFactor = 1.2;
  let reflowTimeout = null;
  
  // Initialize
  setupImageContainers();
  setupZoomButtons();
  
  // Functions
  function setupImageContainers() {
    imageContainers.forEach(container => {
      // Make images clickable for selection
      container.addEventListener('mousedown', handleImageMouseDown);
      container.addEventListener('touchstart', handleImageTouchStart, { passive: false });
      
      // Set initial position to make them float above text
      container.style.zIndex = '10';
      
      // Apply initial shape-outside for text wrapping
      updateShapeOutside(container);
    });
    
    // Handle deselection when clicking outside
    document.addEventListener('click', function(e) {
      if (!e.target.closest('.image-container') && !e.target.closest('.controls')) {
        deselectAllImages();
      }
    });
  }
  
  function setupZoomButtons() {
    zoomInBtn.addEventListener('click', function() {
      if (selectedContainer) {
        // Zoom selected image
        const currentWidth = parseFloat(getComputedStyle(selectedContainer).width);
        selectedContainer.style.width = `${currentWidth * zoomFactor}px`;
        
        // Smooth transition for shape-outside update
        selectedContainer.style.transition = 'width 0.3s ease-in-out';
        
        // Delayed shape-outside update for smoother reflow
        clearTimeout(reflowTimeout);
        reflowTimeout = setTimeout(() => {
          updateShapeOutside(selectedContainer);
        }, 300);
      } else {
        // Zoom entire content
        zoomLevel *= zoomFactor;
        content.style.transform = `scale(${zoomLevel})`;
        content.style.transformOrigin = 'top center';
        content.style.transition = 'transform 0.3s ease-in-out';
      }
    });
    
    zoomOutBtn.addEventListener('click', function() {
      if (selectedContainer) {
        // Zoom out selected image
        const currentWidth = parseFloat(getComputedStyle(selectedContainer).width);
        selectedContainer.style.width = `${currentWidth / zoomFactor}px`;
        
        // Smooth transition for shape-outside update
        selectedContainer.style.transition = 'width 0.3s ease-in-out';
        
        // Delayed shape-outside update for smoother reflow
        clearTimeout(reflowTimeout);
        reflowTimeout = setTimeout(() => {
          updateShapeOutside(selectedContainer);
        }, 300);
      } else {
        // Zoom out entire content
        zoomLevel /= zoomFactor;
        content.style.transform = `scale(${zoomLevel})`;
        content.style.transformOrigin = 'top center';
        content.style.transition = 'transform 0.3s ease-in-out';
      }
    });
  }
  
  function handleImageMouseDown(e) {
    if (e.target.tagName === 'IMG' || e.target.classList.contains('image-container') || e.target.classList.contains('image-caption')) {
      e.preventDefault();
      e.stopPropagation();
      
      const container = e.target.closest('.image-container');
      selectImage(container);
      
      // Start dragging
      isDragging = true;
      startX = e.clientX;
      startY = e.clientY;
      startLeft = parseFloat(getComputedStyle(container).left) || 0;
      startTop = parseFloat(getComputedStyle(container).top) || 0;
      
      // Remove transition during drag start
      container.style.transition = 'none';
      
      // Setup move and end events
      document.addEventListener('mousemove', handleImageMouseMove);
      document.addEventListener('mouseup', handleImageMouseUp);
    }
  }
  
  function handleImageTouchStart(e) {
    if (e.target.tagName === 'IMG' || e.target.classList.contains('image-container') || e.target.classList.contains('image-caption')) {
      e.preventDefault();
      
      const container = e.target.closest('.image-container');
      selectImage(container);
      
      // Start dragging
      isDragging = true;
      startX = e.touches[0].clientX;
      startY = e.touches[0].clientY;
      startLeft = parseFloat(getComputedStyle(container).left) || 0;
      startTop = parseFloat(getComputedStyle(container).top) || 0;
      
      // Remove transition during drag start
      container.style.transition = 'none';
      
      // Setup move and end events
      document.addEventListener('touchmove', handleImageTouchMove, { passive: false });
      document.addEventListener('touchend', handleImageTouchEnd);
    }
  }
  
  // Track last position for throttling
  let lastUpdateTime = 0;
  let lastPosX = 0;
  let lastPosY = 0;
  const updateInterval = 50; // Update text flow every 50ms during drag
  
  function handleImageMouseMove(e) {
    if (!isDragging || !selectedContainer) return;
    
    const dx = e.clientX - startX;
    const dy = e.clientY - startY;
    
    // Update position
    const newLeft = startLeft + dx;
    const newTop = startTop + dy;
    
    // Always update the visual position immediately for smooth dragging
    selectedContainer.style.left = `${newLeft}px`;
    selectedContainer.style.top = `${newTop}px`;
    
    // But throttle the shape-outside updates for smoother text reflow
    const now = Date.now();
    if (now - lastUpdateTime > updateInterval || 
        Math.abs(newLeft - lastPosX) > 30 || 
        Math.abs(newTop - lastPosY) > 30) {
      
      lastPosX = newLeft;
      lastPosY = newTop;
      lastUpdateTime = now;
      
      // Clear any pending updates
      clearTimeout(reflowTimeout);
      
      // Schedule a reflow with a slight delay
      reflowTimeout = setTimeout(() => {
        updateShapeOutside(selectedContainer);
      }, 50);
    }
  }
  
  function handleImageTouchMove(e) {
    if (!isDragging || !selectedContainer) return;
    e.preventDefault();
    
    const dx = e.touches[0].clientX - startX;
    const dy = e.touches[0].clientY - startY;
    
    // Update position
    const newLeft = startLeft + dx;
    const newTop = startTop + dy;
    
    // Always update the visual position immediately for smooth dragging
    selectedContainer.style.left = `${newLeft}px`;
    selectedContainer.style.top = `${newTop}px`;
    
    // But throttle the shape-outside updates for smoother text reflow
    const now = Date.now();
    if (now - lastUpdateTime > updateInterval || 
        Math.abs(newLeft - lastPosX) > 30 || 
        Math.abs(newTop - lastPosY) > 30) {
      
      lastPosX = newLeft;
      lastPosY = newTop;
      lastUpdateTime = now;
      
      // Clear any pending updates
      clearTimeout(reflowTimeout);
      
      // Schedule a reflow with a slight delay
      reflowTimeout = setTimeout(() => {
        updateShapeOutside(selectedContainer);
      }, 50);
    }
  }
  
  function handleImageMouseUp() {
    if (!isDragging || !selectedContainer) return;
    
    // Enable transition again for smooth final positioning
    selectedContainer.style.transition = 'transform 0.3s ease, width 0.3s ease';
    
    // Final update to shape-outside with a slight delay for smooth animation
    clearTimeout(reflowTimeout);
    reflowTimeout = setTimeout(() => {
      updateShapeOutside(selectedContainer);
    }, 100);
    
    isDragging = false;
    document.removeEventListener('mousemove', handleImageMouseMove);
    document.removeEventListener('mouseup', handleImageMouseUp);
  }
  
  function handleImageTouchEnd() {
    if (!isDragging || !selectedContainer) return;
    
    // Enable transition again for smooth final positioning
    selectedContainer.style.transition = 'transform 0.3s ease, width 0.3s ease';
    
    // Final update to shape-outside with a slight delay for smooth animation
    clearTimeout(reflowTimeout);
    reflowTimeout = setTimeout(() => {
      updateShapeOutside(selectedContainer);
    }, 100);
    
    isDragging = false;
    document.removeEventListener('touchmove', handleImageTouchMove);
    document.removeEventListener('touchend', handleImageTouchEnd);
  }
  
  function selectImage(container) {
    // Deselect previous selection
    deselectAllImages();
    
    // Select new image
    selectedContainer = container;
    container.classList.add('selected');
    container.style.zIndex = '20';
  }
  
  function deselectAllImages() {
    imageContainers.forEach(container => {
      container.classList.remove('selected');
      container.style.zIndex = '10';
    });
    selectedContainer = null;
  }
  
  function updateShapeOutside(container) {
    // Calculate the shape-outside polygon based on the container's dimensions
    const rect = container.getBoundingClientRect();
    const parentRect = content.getBoundingClientRect();
    
    // Calculate relative position to parent
    const top = rect.top - parentRect.top;
    const left = rect.left - parentRect.left;
    const right = left + rect.width;
    const bottom = top + rect.height;
    
    // Create a more complex shape-outside with rounded corners for smoother text flow
    // This creates a slight margin around the image for better text wrapping
    const margin = 10; // Margin in pixels
    
    const shapePolygon = `
      polygon(
        ${left - margin}px ${top - margin}px, 
        ${right + margin}px ${top - margin}px, 
        ${right + margin}px ${bottom + margin}px, 
        ${left - margin}px ${bottom + margin}px
      )
    `;
    
    // Apply the shape-outside with a smooth transition
    container.style.shapeOutside = shapePolygon;
    container.style.shapeMargin = '10px'; // Additional margin for smoother text flow
    
    // For wrapping text, we also need to set float
    container.style.float = left < parentRect.width / 2 ? 'left' : 'right';
  }
});

  </script>
</body>
</html>